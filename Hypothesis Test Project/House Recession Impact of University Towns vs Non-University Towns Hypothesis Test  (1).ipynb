{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis:\n",
    "University towns have their mean housing prices less effected by recessions. Run a t-test to compare the ratio of the mean price of houses in university towns the quarter before the recession starts compared to the recession bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function that will import the data and will clean it from inconsistencies and unnecessary punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_university_towns():\n",
    "    \n",
    "    # import data\n",
    "    df = pd.read_table('university_towns.txt',header=None)\n",
    "\n",
    "    dataStorage = []\n",
    "    \n",
    "# Cleaning the dataSet from inconsistent formating and unnecessary elements included in each record. The state\n",
    "# records has the word '[edit]' included, i.e. Texas[edit]. The region records has unnecessary parentheses included, i.e.\n",
    "# Paloma (...). Both state and region information are stored within the same unlabeled column.\n",
    "     \n",
    "    for element in df[0]:\n",
    "    \n",
    "        # Locate state. Split word on the first bracket. Store state name within variable. \n",
    "        if '[edit]' in element:\n",
    "            x = element.split('[')[0]\n",
    "        \n",
    "        # Locate region. Split word on the first parenthese. Store both state and region record within list. \n",
    "        if ' (' in element:\n",
    "            y = element.split(' (')[0]\n",
    "            dataStorage.append((x,y))\n",
    "            \n",
    "        # Locate region that do not include either parentheses or brackets.Store both state and region record within list. \n",
    "        if ' (' not in element and '[edit]' not in element:\n",
    "            dataStorage.append((x,element))\n",
    "    \n",
    "    # Convert list into a dataframe with labeled columns.\n",
    "    tempDF = pd.DataFrame(dataStorage,columns=('State','RegionName'))\n",
    "\n",
    "    return tempDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import GDP data and evaluate each quarter to identify the following 4 features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Start of recession \n",
    "(2) Before the recession started\n",
    "(3) End of recession\n",
    "(4) The bottom of the recession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recession_start():\n",
    "\n",
    "    # Import Data.  \n",
    "    df = pd.read_excel('gdplev.xls',skiprows=7)\n",
    "        \n",
    "    # Rename colomns that will be used.\n",
    "    df = df.rename(index=str,columns={\"Unnamed: 4\":\"Quarterly\",\"Unnamed: 6\":\"GDP 2009_quarterly\"})\n",
    "\n",
    "    # Filter DataSet to include data from the first quarter year 2000  to latest record entry.\n",
    "    df = df[df['Quarterly']>='2000q1']\n",
    "    \n",
    "    # Create new dataframe with specific columns. \n",
    "    df = df[['Quarterly','GDP 2009_quarterly']]\n",
    "\n",
    "    # reset the index and drop the previous index. \n",
    "    df.reset_index(inplace=True)\n",
    "    df.drop('index',axis=1,inplace=True)\n",
    "\n",
    "    # Create new column within dataframe.\n",
    "    df['GDP Change'] = 0\n",
    "\n",
    "    # Stored the difference in GDP between quarters.\n",
    "    for element in range(0,65):\n",
    "        \n",
    "        df['GDP Change'][element+1] = df.loc[element+1]['GDP 2009_quarterly'] - df.loc[element]['GDP 2009_quarterly']\n",
    "\n",
    "        \n",
    "    # Created a new column where the values will be either 'increase' or 'decline', which will be based on the GDP Change. \n",
    "    # This column will help determine where the recession began. A recession is determined to be when there's a decline in \n",
    "    # the GDP for two consecutive quarters.\n",
    "    df['Change'] = 'NaN'\n",
    "    x=0\n",
    "\n",
    "    for element in df['GDP Change']:\n",
    "        \n",
    "        if element >= 0:\n",
    "            df['Change'].loc[x] = 'increase'\n",
    "            x+=1\n",
    "            \n",
    "        else:\n",
    "            df['Change'].loc[x] = 'decline'\n",
    "            x+=1\n",
    "\n",
    "\n",
    "    # Filtering through the newly added column 'Change' to identify the quarter where the GDP was in a decline for two\n",
    "    # consecutive quarters.\n",
    "    \n",
    "    s1='decline'\n",
    "    s2='increase'\n",
    "    x=0\n",
    "    dataStorage=[]\n",
    "    for element in df['Change']:\n",
    "\n",
    "        if element==s1 and df['Change'].loc[x+1]==s1:\n",
    "\n",
    "            recession_start = df.loc[x]['Quarterly']\n",
    "            before_recession = df.loc[x-1]['Quarterly']\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            x+=1    \n",
    "            \n",
    "            \n",
    "    # Identifying the quarter where the recession ended, which is when the GDP is in a decline for two consecutive \n",
    "    # quarters followed by an increase in two consecutive quarters.\n",
    "    x=0\n",
    "    for element in df['Change']:\n",
    "\n",
    "        if element==s1 and df['Change'].loc[x+1]==s1 and df['Change'].loc[x+2]==s2 and df['Change'].loc[x+3]==s2:\n",
    "\n",
    "            recession_end = df.loc[x+3]['Quarterly']\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            x+=1\n",
    "            \n",
    "    # Identifying the quarter where the recession bottom occurs, which is when the GDP is in a decline for two consecutive \n",
    "    # quarters followed by an increase in the following quarter.\n",
    "    x=0\n",
    "    for element in df['Change']:\n",
    "\n",
    "        if element==s1 and df['Change'].loc[x+1]==s1 and df['Change'].loc[x+2]==s2:\n",
    "\n",
    "            recession_bottom = df.loc[x+1]['Quarterly']\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            x+=1\n",
    "\n",
    "    \n",
    "    return recession_start,before_recession,recession_end,recession_bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Housing data and perform data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_housing_data_to_quarters():\n",
    "    \n",
    "    # import dataSet\n",
    "    df = pd.read_csv('City_Zhvi_AllHomes.csv')\n",
    "    \n",
    "    # keys that will be used to change the state's appreviation to the state's full name.\n",
    "    states = {'OH': 'Ohio', 'KY': 'Kentucky', 'AS': 'American Samoa', 'NV': 'Nevada', 'WY': 'Wyoming', \n",
    "              'NA': 'National', 'AL': 'Alabama', 'MD': 'Maryland', 'AK': 'Alaska', 'UT': 'Utah', \n",
    "              'OR': 'Oregon', 'MT': 'Montana', 'IL': 'Illinois', 'TN': 'Tennessee', 'DC': 'District of Columbia',\n",
    "              'VT': 'Vermont', 'ID': 'Idaho', 'AR': 'Arkansas', 'ME': 'Maine', 'WA': 'Washington', 'HI': 'Hawaii',\n",
    "              'WI': 'Wisconsin', 'MI': 'Michigan', 'IN': 'Indiana', 'NJ': 'New Jersey', 'AZ': 'Arizona',\n",
    "              'GU': 'Guam', 'MS': 'Mississippi', 'PR': 'Puerto Rico', 'NC': 'North Carolina', 'TX': 'Texas',\n",
    "              'SD': 'South Dakota', 'MP': 'Northern Mariana Islands', 'IA': 'Iowa', 'MO': 'Missouri',\n",
    "              'CT': 'Connecticut', 'WV': 'West Virginia', 'SC': 'South Carolina', 'LA': 'Louisiana', 'KS': 'Kansas',\n",
    "              'NY': 'New York', 'NE': 'Nebraska', 'OK': 'Oklahoma', 'FL': 'Florida', 'CA': 'California',\n",
    "              'CO': 'Colorado', 'PA': 'Pennsylvania', 'DE': 'Delaware', 'NM': 'New Mexico', 'RI': 'Rhode Island',\n",
    "              'MN': 'Minnesota', 'VI': 'Virgin Islands', 'NH': 'New Hampshire', 'MA': 'Massachusetts', 'GA': 'Georgia',\n",
    "              'ND': 'North Dakota', 'VA': 'Virginia'}\n",
    "\n",
    "    # Mapping the keys to the 'State' column.\n",
    "    df['State'] = df['State'].map(states)\n",
    "\n",
    "    # Setting the state and region name to be the index of the dataframe. \n",
    "    df.set_index((['State','RegionName']),inplace=True)\n",
    "\n",
    "    x=df.columns\n",
    "\n",
    "    # Selecting the names of the columns from year 2000 to 2016. \n",
    "    sel_cols = x[(x>='2000-01') & (x<='2016-08')]\n",
    "\n",
    "    # Used the previous column selection to create a new dataframe.\n",
    "    df = df[sel_cols]\n",
    "\n",
    "    # Columns converted from string to date_time. This is done in order to use the 'resample()' function.\n",
    "    df = df[df.columns].rename(columns=pd.to_datetime)\n",
    "\n",
    "    # resampled the data in quarterly intervals to determine the mean.\n",
    "    mdf = df[df.columns].resample('Q',axis=1).mean()\n",
    "\n",
    "    # Converted the columns from a date_time back to a string, in it's original formate of '%Y-%M' and stored it.\n",
    "    sColumns = mdf.columns.strftime('%Y-%m')\n",
    "\n",
    "    # stored the columns as a date_time\n",
    "    tsColumns =  mdf.columns\n",
    "\n",
    "    counter=0\n",
    "\n",
    "    \n",
    "    # Renamed the date_time column back to it's series name for the dataframe.\n",
    "    for element in range(0,len(sColumns)):\n",
    "\n",
    "        mdf = mdf.rename(index=str,columns={tsColumns[counter]:sColumns[counter]},)\n",
    "        counter+=1\n",
    "\n",
    "    # Stored the columns to the new dataframe.\n",
    "    x1 = mdf.columns \n",
    "\n",
    "    # Split each column name by a dash '-' in order to store the year and month separately in a list.\n",
    "    # i.e. 2015-01 -> ['2015','01']\n",
    "    for element in range(0,len(x1)):\n",
    "\n",
    "        x = x1[element]\n",
    "\n",
    "        y = x1[element].split('-')\n",
    "\n",
    "        # Converting the month, second element in the list, to it's respective quarter then renaming the dataframe column\n",
    "        # to it's updated format. i.e. 2015-01 -> ['2015','01'] -> 2015q1\n",
    "        if y[1]=='01' or  y[1]=='02' or  y[1]=='03':\n",
    "\n",
    "            y[1] = 'q1'\n",
    "            y = y[0]+y[1]\n",
    "\n",
    "            mdf = mdf.rename(index=str,columns={x:y},)\n",
    "\n",
    "        elif y[1]=='04' or  y[1]=='05' or  y[1]=='06':\n",
    "\n",
    "            y[1] = 'q2'\n",
    "            y = y[0]+y[1]\n",
    "\n",
    "            mdf = mdf.rename(index=str,columns={x:y},)\n",
    "\n",
    "        elif y[1]=='07' or  y[1]=='08' or  y[1]=='09':\n",
    "\n",
    "            y[1] = 'q3'\n",
    "            y = y[0]+y[1]\n",
    "\n",
    "            mdf = mdf.rename(index=str,columns={x:y},)\n",
    "\n",
    "        elif y[1]=='10' or  y[1]=='11' or  y[1]=='12':\n",
    "\n",
    "            y[1] = 'q4'\n",
    "            y = y[0]+y[1]\n",
    "\n",
    "            mdf = mdf.rename(index=str,columns={x:y},)\n",
    "            \n",
    "    return mdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conduct T-Test to determine whether we reject or fail to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_ttest():\n",
    "\n",
    "    # Imported data from previously created functions that cleaned and formatted the dataset.\n",
    "\n",
    "    # rs -> recession start, br -> before recession, re -> recession end, rbb -> recession bottom\n",
    "    rs,br,re,rb = get_recession_start() \n",
    "    ut = get_list_of_university_towns()\n",
    "    house_df = convert_housing_data_to_quarters()\n",
    "\n",
    "    # Filtering the housing dataset to include the quarter before the recession began and the recession bottom.\n",
    "    house_df = house_df[[br,rb]]\n",
    "\n",
    "    # Created a price ratio column to compare the pricing of homes before the recession occured to the end of the recession.\n",
    "    house_df['PriceRatio'] = house_df[br].div(house_df[rb])\n",
    "\n",
    "\n",
    "    # Convert the records of university town, excluding the index, to be stored as a list. i.e. [(state,region)...]\n",
    "    subset_list = ut.to_records(index=False).tolist()\n",
    "\n",
    "    # Created new dataframe to include records in house_df that exist in university towns.\n",
    "    university_towns = house_df.loc[subset_list] \n",
    "\n",
    "    # Created new dataframe to includes records of house_df but excluding those that exist in university towns. For example, \n",
    "    # (Alaska, Fairbanks) exist in university_towns therefore it will not be included in non_university_towns.\n",
    "    non_university_towns = house_df.loc[~house_df.index.isin(subset_list)] \n",
    "\n",
    "    # Stored the statistic value and p value from the T-Test.  \n",
    "    stat,pvalue = stats.ttest_ind(university_towns['PriceRatio'],non_university_towns['PriceRatio'],nan_policy='omit')\n",
    "\n",
    "    # pvalue condition statement. If less then 0.01 then we can reject the 'null hypothesis'. If above 0.01 then we failed  \n",
    "    # to reject the 'null hypothesis'.\n",
    "    different = pvalue < 0.01\n",
    "\n",
    "\n",
    "    # Compared the mean value of price ratio of university_towns vs non_university_towns in order to determine which group \n",
    "    # was less affected in terms of housing price.\n",
    "    if university_towns['PriceRatio'].mean() < non_university_towns['PriceRatio'].mean():\n",
    "\n",
    "        better = 'university town'\n",
    "\n",
    "    else:\n",
    "\n",
    "        better = 'non-university town'\n",
    "\n",
    "\n",
    "    return (different, pvalue, better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Python\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "F:\\Python\\lib\\site-packages\\pandas\\core\\indexing.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, 0.002724063704753125, 'university town')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_ttest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Full Disclosure: The project was completed as part of a milestone project for a Coursera Data Scientist course.  \n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
